---
title: "Statistics: The Science of Decisions"
author: "Ramesh Natarajan"
date: "Saturday, September 24, 2016"
output: pdf_document
---

### Background Information
In a Stroop task, participants are presented with a list of words, with each word displayed in a color of ink. The participant's task is to say out loud the color of the ink in which the word is printed. The task has two conditions: a congruent words condition, and an incongruent words condition. In the congruent words condition, the words being displayed are color words whose names match the colors in which they are printed: for example RED, BLUE. In the incongruent words condition, the words displayed are color words whose names do not match the colors in which they are printed: for example PURPLE, ORANGE. In each case, we measure the time it takes to name the ink colors in equally-sized lists. Each participant will go through and record a time from each condition.

### Questions for Investigation

```{r}
# Download training and testing files if they are not already downloaded

if (!file.exists("./pml-training.csv")) {
                 download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", "./pml-training.csv")
                 
}

if (!file.exists("./pml-testing.csv")) {
                 download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", "./pml-testing.csv")
                
}
# Read training and test set rationalizing missing values

training <- read.table("./pml-training.csv", header=TRUE, sep = ",", na.strings = c("NA", "#DIV/0!", ""))

testing <- read.table("./pml-testing.csv", header=TRUE, sep = ",", na.strings = c("NA", "#DIV/0!", ""))
```

### Cleaning Data for relevant feature selection

We will clean the training data and extract only columns that have meaningful data for our model fitting 

```{r}

# remove all columns from analysis that have more than 50% missing values or that are not relevant for the analysis (columns 1 to 7)

badcols <- NULL

dlen <- length(training)
for (Var in names(training)) {
    missing <- sum(is.na(training[,Var]))
    if (missing > dlen/2) {
      badcols <- c(badcols, Var)
    }
}
trnClean <- training[, !(names(training) %in% badcols)]
trnClean <- trnClean[, -c(1:7)]

```
### Model fitting, accuracy check and cross validation

In the next section, we will split the data into training and testing set and fit a model using random forest due to its high accuracy. 

```{r cache=TRUE, warning=FALSE}
library(caret)
library(randomForest)

# Split data into training and testing set

inTrain <- createDataPartition(y=trnClean$classe, p=0.7, list = FALSE)

trainingSet <- trnClean[inTrain, ]
testingSet <- trnClean[-inTrain, ]

# Fit a model using random forest

set.seed(3873)
modFitRF <- randomForest(classe ~. , proximity = TRUE, data=trainingSet, importance = TRUE)

layout(matrix(c(1,2),nrow=1),width=c(4,1)) 
par(mar=c(5,4,4,0)) #No margin on the right side
plot(modFitRF, log="y", main = "Random Forest Model error rate split", sub = " Error rate by classe")
par(mar=c(5,0,4,2)) #No margin on the left side
plot(c(0,1),type="n", axes=F, xlab="", ylab="")
legend("top", colnames(modFitRF$err.rate),col=1:6,cex=0.8,fill=1:6)

print(modFitRF)
```
The graph shows very low error rate with 500 tree classification across activity quality. Also, the model shows that the OOB estimate of error rate is 0.63% on the training set. We will now perform a cross validation on out of sample data to check accuracy.


```{r}
pred <- predict(modFitRF, testingSet, type = "class")

confusionMatrix(pred, testingSet$classe)

```
An accuracy of .99 on out of sample data shows that the model provides a high degree of accuracy for the estimate.

Having cross validated the model, we can now proceed to predict the "classe" variable (activity quality) for the test data provided for this assignment.

```{r}
answers <- predict(modFitRF, testing, type="class")

## function for writing files with prediction for each row of data
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}

## write 20 files with prediction values for each test row to current directory

pml_write_files(answers)
```

